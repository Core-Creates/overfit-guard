{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit Guard - Universal Dataset Demo\n",
    "\n",
    "**Run Overfit Guard on ANY dataset - Built-in or Custom!**\n",
    "\n",
    "This notebook lets you:\n",
    "- Choose from built-in datasets (Classification & Regression)\n",
    "- Upload your own CSV dataset\n",
    "- Select framework (PyTorch, Keras, or scikit-learn)\n",
    "- Compare training WITH vs WITHOUT overfit protection\n",
    "- See automatic overfitting detection and correction in action\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Core-Creates/overfit-guard/blob/main/notebooks/universal_dataset_demo.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install Overfit Guard and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install from GitHub repo (always gets latest version)\n",
    "!pip install git+https://github.com/Core-Creates/overfit-guard.git\n",
    "\n",
    "# Install ML frameworks\n",
    "!pip install scikit-learn pandas matplotlib seaborn torch torchvision tensorflow\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration - Choose Your Setup\n",
    "\n",
    "**Customize these settings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "# DATASET SELECTION\n",
    "# Built-in options: 'breast_cancer', 'digits', 'wine', 'iris', 'diabetes', 'california_housing', 'custom'\n",
    "DATASET = 'breast_cancer'  # Change this!\n",
    "\n",
    "# FRAMEWORK SELECTION\n",
    "# Options: 'pytorch', 'keras', 'sklearn'\n",
    "FRAMEWORK = 'pytorch'  # Change this!\n",
    "\n",
    "# TRAINING SETTINGS\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# CUSTOM DATASET (only used if DATASET='custom')\n",
    "CUSTOM_CSV_PATH = None  # Set to your CSV file path\n",
    "TARGET_COLUMN = 'target'  # Name of target column in CSV\n",
    "\n",
    "# ===================================\n",
    "\n",
    "print(f\"‚úì Dataset: {DATASET}\")\n",
    "print(f\"‚úì Framework: {FRAMEWORK}\")\n",
    "print(f\"‚úì Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "Load your chosen dataset (or upload custom):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_dataset(dataset_name, custom_path=None, target_col='target'):\n",
    "    \"\"\"Load dataset and return X, y, task_type, num_classes.\"\"\"\n",
    "    \n",
    "    if dataset_name == 'custom':\n",
    "        # Load custom CSV\n",
    "        if custom_path is None:\n",
    "            # Try to upload in Colab\n",
    "            try:\n",
    "                from google.colab import files\n",
    "                uploaded = files.upload()\n",
    "                custom_path = list(uploaded.keys())[0]\n",
    "            except:\n",
    "                raise ValueError(\"Please provide CUSTOM_CSV_PATH or upload a file\")\n",
    "        \n",
    "        df = pd.read_csv(custom_path)\n",
    "        X = df.drop(columns=[target_col]).values\n",
    "        y = df[target_col].values\n",
    "        \n",
    "        # Detect task type\n",
    "        num_unique = len(np.unique(y))\n",
    "        if num_unique <= 20:\n",
    "            task_type = 'classification'\n",
    "            num_classes = num_unique\n",
    "        else:\n",
    "            task_type = 'regression'\n",
    "            num_classes = 1\n",
    "            \n",
    "        print(f\"üìÅ Loaded custom dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        \n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = datasets.load_breast_cancer()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'classification'\n",
    "        num_classes = 2\n",
    "        print(f\"üìÅ Wisconsin Breast Cancer: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        \n",
    "    elif dataset_name == 'digits':\n",
    "        data = datasets.load_digits()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'classification'\n",
    "        num_classes = 10\n",
    "        print(f\"üìÅ Digits Dataset: {X.shape[0]} samples, {X.shape[1]} features, 10 classes\")\n",
    "        \n",
    "    elif dataset_name == 'wine':\n",
    "        data = datasets.load_wine()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'classification'\n",
    "        num_classes = 3\n",
    "        print(f\"üìÅ Wine Dataset: {X.shape[0]} samples, {X.shape[1]} features, 3 classes\")\n",
    "        \n",
    "    elif dataset_name == 'iris':\n",
    "        data = datasets.load_iris()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'classification'\n",
    "        num_classes = 3\n",
    "        print(f\"üìÅ Iris Dataset: {X.shape[0]} samples, {X.shape[1]} features, 3 classes\")\n",
    "        \n",
    "    elif dataset_name == 'diabetes':\n",
    "        data = datasets.load_diabetes()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'regression'\n",
    "        num_classes = 1\n",
    "        print(f\"üìÅ Diabetes Dataset: {X.shape[0]} samples, {X.shape[1]} features (regression)\")\n",
    "        \n",
    "    elif dataset_name == 'california_housing':\n",
    "        data = datasets.fetch_california_housing()\n",
    "        X, y = data.data, data.target\n",
    "        task_type = 'regression'\n",
    "        num_classes = 1\n",
    "        print(f\"üìÅ California Housing: {X.shape[0]} samples, {X.shape[1]} features (regression)\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "    \n",
    "    return X, y, task_type, num_classes\n",
    "\n",
    "# Load the dataset\n",
    "X, y, task_type, num_classes = load_dataset(DATASET, CUSTOM_CSV_PATH, TARGET_COLUMN)\n",
    "\n",
    "# Split into train/val/test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úì Task Type: {task_type}\")\n",
    "print(f\"‚úì Train: {X_train.shape[0]} samples\")\n",
    "print(f\"‚úì Val: {X_val.shape[0]} samples\")\n",
    "print(f\"‚úì Test: {X_test.shape[0]} samples\")\n",
    "print(f\"‚úì Features: {X_train.shape[1]}\")\n",
    "if task_type == 'classification':\n",
    "    print(f\"‚úì Classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Model\n",
    "\n",
    "Automatically create a model for your chosen framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = num_classes if task_type == 'classification' else 1\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    \n",
    "    class UniversalNet(nn.Module):\n",
    "        def __init__(self, input_size, output_size, task_type):\n",
    "            super().__init__()\n",
    "            hidden1 = min(64, input_size * 4)\n",
    "            hidden2 = min(32, input_size * 2)\n",
    "            hidden3 = min(16, input_size)\n",
    "            \n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden1),\n",
    "                nn.BatchNorm1d(hidden1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                \n",
    "                nn.Linear(hidden1, hidden2),\n",
    "                nn.BatchNorm1d(hidden2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                \n",
    "                nn.Linear(hidden2, hidden3),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                \n",
    "                nn.Linear(hidden3, output_size)\n",
    "            )\n",
    "            self.task_type = task_type\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "    \n",
    "    print(f\"üî® Created PyTorch model ({input_size} ‚Üí {output_size})\")\n",
    "\n",
    "elif FRAMEWORK == 'keras':\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def create_keras_model(input_size, output_size, task_type):\n",
    "        hidden1 = min(64, input_size * 4)\n",
    "        hidden2 = min(32, input_size * 2)\n",
    "        hidden3 = min(16, input_size)\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(hidden1, activation='relu', input_shape=(input_size,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Dense(hidden2, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Dense(hidden3, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Dense(output_size, activation='softmax' if task_type == 'classification' else None)\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    print(f\"üî® Created Keras model ({input_size} ‚Üí {output_size})\")\n",
    "\n",
    "elif FRAMEWORK == 'sklearn':\n",
    "    from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "    \n",
    "    hidden1 = min(64, input_size * 4)\n",
    "    hidden2 = min(32, input_size * 2)\n",
    "    \n",
    "    print(f\"üî® Created sklearn model ({input_size} ‚Üí {output_size})\")\n",
    "\n",
    "print(\"‚úÖ Model architecture ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Functions\n",
    "\n",
    "Framework-specific training functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Storage for results\n",
    "history_with_guard = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "history_without_guard = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    from overfit_guard.integrations.pytorch import create_pytorch_monitor\n",
    "    \n",
    "    def train_pytorch(use_guard=True, verbose=True):\n",
    "        # Create model\n",
    "        model = UniversalNet(input_size, output_size, task_type)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        if task_type == 'classification':\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            metric_name = 'accuracy'\n",
    "        else:\n",
    "            criterion = nn.MSELoss()\n",
    "            metric_name = 'mse'\n",
    "        \n",
    "        # Create monitor\n",
    "        monitor = None\n",
    "        if use_guard:\n",
    "            monitor = create_pytorch_monitor(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                config={'auto_correct': True, 'log_level': 'WARNING'},\n",
    "                auto_correct=True\n",
    "            )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_data = TensorDataset(\n",
    "            torch.FloatTensor(X_train),\n",
    "            torch.LongTensor(y_train) if task_type == 'classification' else torch.FloatTensor(y_train)\n",
    "        )\n",
    "        val_data = TensorDataset(\n",
    "            torch.FloatTensor(X_val),\n",
    "            torch.LongTensor(y_val) if task_type == 'classification' else torch.FloatTensor(y_val)\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        history = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if task_type == 'classification':\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    train_correct += predicted.eq(targets).sum().item()\n",
    "                else:\n",
    "                    loss = criterion(outputs.squeeze(), targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_total += targets.size(0)\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_metric = train_correct / train_total if task_type == 'classification' else train_loss\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    if task_type == 'classification':\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_correct += predicted.eq(targets).sum().item()\n",
    "                    else:\n",
    "                        loss = criterion(outputs.squeeze(), targets)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_total += targets.size(0)\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            val_metric = val_correct / val_total if task_type == 'classification' else val_loss\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_metric'].append(train_metric)\n",
    "            history['val_metric'].append(val_metric)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {train_loss:.4f}/{val_loss:.4f} - {metric_name}: {train_metric:.4f}/{val_metric:.4f}\")\n",
    "            \n",
    "            # Monitor check\n",
    "            if monitor:\n",
    "                results = monitor.on_epoch_end(\n",
    "                    epoch, model,\n",
    "                    {'loss': train_loss, metric_name: train_metric},\n",
    "                    {'loss': val_loss, metric_name: val_metric}\n",
    "                )\n",
    "                \n",
    "                if monitor.should_stop:\n",
    "                    if verbose:\n",
    "                        print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "        \n",
    "        # Test evaluation\n",
    "        test_data = TensorDataset(\n",
    "            torch.FloatTensor(X_test),\n",
    "            torch.LongTensor(y_test) if task_type == 'classification' else torch.FloatTensor(y_test)\n",
    "        )\n",
    "        test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                if task_type == 'classification':\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    test_correct += predicted.eq(targets).sum().item()\n",
    "                test_total += targets.size(0)\n",
    "        \n",
    "        test_metric = test_correct / test_total if task_type == 'classification' else 0\n",
    "        \n",
    "        return history, test_metric, monitor\n",
    "\n",
    "elif FRAMEWORK == 'keras':\n",
    "    from overfit_guard.integrations.keras import create_keras_monitor\n",
    "    \n",
    "    def train_keras(use_guard=True, verbose=True):\n",
    "        model = create_keras_model(input_size, output_size, task_type)\n",
    "        \n",
    "        if task_type == 'classification':\n",
    "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            metric_name = 'accuracy'\n",
    "        else:\n",
    "            model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "            metric_name = 'mse'\n",
    "        \n",
    "        callbacks = []\n",
    "        if use_guard:\n",
    "            monitor = create_keras_monitor(auto_correct=True, verbose=verbose)\n",
    "            callbacks.append(monitor)\n",
    "        \n",
    "        hist = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1 if verbose else 0\n",
    "        )\n",
    "        \n",
    "        # Convert history\n",
    "        history = {\n",
    "            'train_loss': hist.history['loss'],\n",
    "            'val_loss': hist.history['val_loss'],\n",
    "            'train_metric': hist.history[metric_name],\n",
    "            'val_metric': hist.history[f'val_{metric_name}']\n",
    "        }\n",
    "        \n",
    "        # Test\n",
    "        test_result = model.evaluate(X_test, y_test, verbose=0)\n",
    "        test_metric = test_result[1]  # Second value is metric\n",
    "        \n",
    "        return history, test_metric, monitor if use_guard else None\n",
    "\n",
    "elif FRAMEWORK == 'sklearn':\n",
    "    from overfit_guard.integrations.sklearn import create_sklearn_monitor\n",
    "    from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "    \n",
    "    def train_sklearn(use_guard=True, verbose=True):\n",
    "        if task_type == 'classification':\n",
    "            model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1, warm_start=True, random_state=42)\n",
    "            metric_func = accuracy_score\n",
    "            metric_name = 'accuracy'\n",
    "        else:\n",
    "            model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1, warm_start=True, random_state=42)\n",
    "            metric_func = mean_squared_error\n",
    "            metric_name = 'mse'\n",
    "        \n",
    "        monitor = None\n",
    "        if use_guard:\n",
    "            monitor = create_sklearn_monitor(\n",
    "                metric_name=metric_name,\n",
    "                higher_is_better=(task_type == 'classification')\n",
    "            )\n",
    "        \n",
    "        history = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            train_pred = model.predict(X_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            \n",
    "            train_metric = metric_func(y_train, train_pred)\n",
    "            val_metric = metric_func(y_val, val_pred)\n",
    "            \n",
    "            train_loss = model.loss_ if hasattr(model, 'loss_') else 0\n",
    "            val_loss = val_metric if task_type == 'regression' else 1 - val_metric\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_metric'].append(train_metric)\n",
    "            history['val_metric'].append(val_metric)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - {metric_name}: {train_metric:.4f}/{val_metric:.4f}\")\n",
    "            \n",
    "            if monitor:\n",
    "                results = monitor.check_iteration(\n",
    "                    epoch,\n",
    "                    {metric_name: train_metric},\n",
    "                    {metric_name: val_metric},\n",
    "                    model\n",
    "                )\n",
    "                \n",
    "                if monitor.should_stop:\n",
    "                    if verbose:\n",
    "                        print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "        \n",
    "        # Test\n",
    "        test_pred = model.predict(X_test)\n",
    "        test_metric = metric_func(y_test, test_pred)\n",
    "        \n",
    "        return history, test_metric, monitor\n",
    "\n",
    "print(\"‚úÖ Training functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Training - WITHOUT Guard\n",
    "\n",
    "Baseline training without overfitting protection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Training WITHOUT Overfit Guard...\\n\")\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    history_without_guard, test_without, _ = train_pytorch(use_guard=False)\n",
    "elif FRAMEWORK == 'keras':\n",
    "    history_without_guard, test_without, _ = train_keras(use_guard=False)\n",
    "elif FRAMEWORK == 'sklearn':\n",
    "    history_without_guard, test_without, _ = train_sklearn(use_guard=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline training complete!\")\n",
    "print(f\"Test {metric_name}: {test_without:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Training - WITH Guard\n",
    "\n",
    "Training with automatic overfitting detection and correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üõ°Ô∏è Training WITH Overfit Guard...\\n\")\n",
    "\n",
    "if FRAMEWORK == 'pytorch':\n",
    "    history_with_guard, test_with, monitor = train_pytorch(use_guard=True)\n",
    "elif FRAMEWORK == 'keras':\n",
    "    history_with_guard, test_with, monitor = train_keras(use_guard=True)\n",
    "elif FRAMEWORK == 'sklearn':\n",
    "    history_with_guard, test_with, monitor = train_sklearn(use_guard=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Protected training complete!\")\n",
    "print(f\"Test {metric_name}: {test_with:.4f}\")\n",
    "\n",
    "if monitor:\n",
    "    summary = monitor.monitor.get_summary() if hasattr(monitor, 'monitor') else monitor.monitor_obj.get_summary() if hasattr(monitor, 'monitor_obj') else {}\n",
    "    if summary:\n",
    "        print(f\"\\nüìä Overfit Guard Summary:\")\n",
    "        print(f\"  - Overfitting detected: {summary.get('overfitting_detected', 0)} times\")\n",
    "        print(f\"  - Corrections applied: {summary.get('corrections_applied', 0)}\")\n",
    "        print(f\"  - Overfitting rate: {summary.get('overfitting_rate', 0):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results\n",
    "\n",
    "Compare training with and without protection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle(f'{DATASET.upper()} Dataset - {FRAMEWORK.upper()} Training Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# WITHOUT Guard - Loss\n",
    "axes[0, 0].plot(history_without_guard['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history_without_guard['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_title('WITHOUT Overfit Guard - Loss', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# WITHOUT Guard - Metric\n",
    "axes[0, 1].plot(history_without_guard['train_metric'], label=f'Train {metric_name}', linewidth=2)\n",
    "axes[0, 1].plot(history_without_guard['val_metric'], label=f'Val {metric_name}', linewidth=2)\n",
    "axes[0, 1].set_title(f'WITHOUT Overfit Guard - {metric_name.upper()}', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel(metric_name.upper())\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# WITH Guard - Loss\n",
    "axes[1, 0].plot(history_with_guard['train_loss'], label='Train Loss', linewidth=2, color='green')\n",
    "axes[1, 0].plot(history_with_guard['val_loss'], label='Val Loss', linewidth=2, color='orange')\n",
    "axes[1, 0].set_title('WITH Overfit Guard - Loss', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# WITH Guard - Metric\n",
    "axes[1, 1].plot(history_with_guard['train_metric'], label=f'Train {metric_name}', linewidth=2, color='green')\n",
    "axes[1, 1].plot(history_with_guard['val_metric'], label=f'Val {metric_name}', linewidth=2, color='orange')\n",
    "axes[1, 1].set_title(f'WITH Overfit Guard - {metric_name.upper()}', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel(metric_name.upper())\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET}_{FRAMEWORK}_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Plot saved as: {DATASET}_{FRAMEWORK}_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Comparison\n",
    "\n",
    "Summary of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"FINAL RESULTS - {DATASET.upper()} on {FRAMEWORK.upper()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate gaps\n",
    "final_gap_without = abs(history_without_guard['train_metric'][-1] - history_without_guard['val_metric'][-1])\n",
    "final_gap_with = abs(history_with_guard['train_metric'][-1] - history_with_guard['val_metric'][-1])\n",
    "gap_reduction = ((final_gap_without - final_gap_with) / final_gap_without * 100) if final_gap_without > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä WITHOUT Overfit Guard:\")\n",
    "print(f\"  Test {metric_name}: {test_without:.4f}\")\n",
    "print(f\"  Train-Val Gap: {final_gap_without:.4f}\")\n",
    "print(f\"  Epochs Trained: {len(history_without_guard['train_loss'])}\")\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è WITH Overfit Guard:\")\n",
    "print(f\"  Test {metric_name}: {test_with:.4f}\")\n",
    "print(f\"  Train-Val Gap: {final_gap_with:.4f}\")\n",
    "print(f\"  Epochs Trained: {len(history_with_guard['train_loss'])}\")\n",
    "\n",
    "print(f\"\\nüìà Improvement:\")\n",
    "metric_change = test_with - test_without\n",
    "print(f\"  Test {metric_name} Change: {metric_change:+.4f} ({metric_change/test_without*100:+.2f}%)\")\n",
    "print(f\"  Gap Reduction: {gap_reduction:.1f}%\")\n",
    "\n",
    "if monitor:\n",
    "    print(f\"\\nüîç Detection Details:\")\n",
    "    print(f\"  Overfitting Events: {summary.get('overfitting_detected', 0)}\")\n",
    "    print(f\"  Auto-Corrections: {summary.get('corrections_applied', 0)}\")\n",
    "    print(f\"  Detection Rate: {summary.get('overfitting_rate', 0):.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "**What just happened?**\n",
    "\n",
    "1. Loaded dataset and split into train/val/test\n",
    "2. Trained baseline model WITHOUT protection\n",
    "3. Trained protected model WITH Overfit Guard\n",
    "4. Compared performance metrics\n",
    "\n",
    "**Overfit Guard automatically:**\n",
    "- Monitors train-validation gap every epoch\n",
    "- Detects overfitting patterns in real-time\n",
    "- Applies corrections (regularization, learning rate adjustment)\n",
    "- Triggers early stopping when appropriate\n",
    "\n",
    "**Try it with your own data:**\n",
    "1. Set `DATASET = 'custom'`\n",
    "2. Upload your CSV file\n",
    "3. Specify target column name\n",
    "4. Run all cells!\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to use Overfit Guard in production?**\n",
    "\n",
    "```bash\n",
    "pip install overfit-guard\n",
    "```\n",
    "\n",
    "Check out the [GitHub repository](https://github.com/Core-Creates/overfit-guard) for more examples and documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Key Takeaways\n\n**What just happened?**\n\n1. Loaded dataset and split into train/val/test\n2. Trained baseline model WITHOUT protection\n3. Trained protected model WITH Overfit Guard\n4. Compared performance metrics\n5. **NEW:** Generated professional reports in multiple styles!\n\n**Overfit Guard automatically:**\n- Monitors train-validation gap every epoch\n- Detects overfitting patterns in real-time\n- Applies corrections (regularization, learning rate adjustment)\n- Triggers early stopping when appropriate\n- **NEW:** Generates publication-ready reports for any use case!\n\n**Professional Reporting Features:**\n- ‚úÖ **Research Style:** Clean, precise, ready for academic papers\n- ‚úÖ **Marketing Style:** Executive-friendly with ROI analysis\n- ‚úÖ **Debug Style:** Detailed diagnostics for troubleshooting\n- ‚úÖ **Multi-Format Export:** JSON, CSV, HTML, Markdown, LaTeX\n- ‚úÖ **Model Cards:** Compliance-ready documentation\n\n**Try it with your own data:**\n1. Set `DATASET = 'custom'`\n2. Upload your CSV file\n3. Specify target column name\n4. Run all cells!\n5. Generate professional reports for your use case!\n\n---\n\n**Ready to use Overfit Guard in production?**\n\n```bash\npip install overfit-guard\n```\n\n**Learn more:**\n- üìñ [Documentation](https://github.com/Core-Creates/overfit-guard)\n- üíº [Enterprise Solutions](https://github.com/Core-Creates/overfit-guard/blob/main/ENTERPRISE_BUSINESS_STRATEGY.md)\n- üìä [Analysis Reports](https://github.com/Core-Creates/overfit-guard/blob/main/ANALYSIS_REPORT.md)\n- üöÄ [Get Started](https://github.com/Core-Creates/overfit-guard#quick-start)\n\n---\n\n**Upgrade to Professional tier for:**\n- Advanced reporting suite (LaTeX, PDF exports)\n- Cloud integration & dashboards\n- Priority support\n- Commercial license\n\nStarting at $49/month ‚Üí [Learn More](https://github.com/Core-Creates/overfit-guard/blob/main/ENTERPRISE_BUSINESS_STRATEGY.md)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Export to multiple formats\nfrom overfit_guard.reporting import ReportExporter\n\nexporter = ReportExporter()\n\n# Export to JSON (for APIs)\nexporter.to_json(summary, 'results.json', pretty=True)\nprint(\"‚úÖ Exported to results.json\")\n\n# Export to CSV (for spreadsheets)\nexporter.to_csv(summary, 'results.csv')\nprint(\"‚úÖ Exported to results.csv\")\n\n# Generate Markdown table\nmd_table = exporter.to_markdown_table(summary)\nprint(\"\\nüìä Markdown Table:\")\nprint(md_table)\n\n# Generate HTML table\nhtml_table = exporter.to_html_table(summary)\nprint(\"\\n‚úÖ HTML table generated (view in results.html)\")\n\nprint(\"\\nüéâ Professional reporting complete!\")\nprint(\"\\nUse cases:\")\nprint(\"- Research: Use 'research' style for papers, include LaTeX table generation\")\nprint(\"- Marketing: Use 'marketing' style for stakeholders, ROI analysis\")\nprint(\"- Debug: Use 'debug' style for troubleshooting, detailed logs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Export Results\nSave results in multiple formats for sharing and analysis:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Debug style - for troubleshooting\nprint_overfit_guard_summary(summary, style=\"debug\", include_recommendations=False)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Debug Style Report\nFor troubleshooting and internal diagnostics - raw structured data:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Marketing style - for executives and stakeholders\nprint_overfit_guard_summary(summary, style=\"marketing\", include_recommendations=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Marketing Style Report\nFor executives, stakeholders, and demos - story-driven with emojis:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Research style - for academic papers\nprint_overfit_guard_summary(summary, style=\"research\", include_recommendations=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Research Style Report\nFor academic papers and technical documentation - clean, precise, no emojis:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import professional reporting module\nfrom overfit_guard.reporting import (\n    compute_overfit_guard_summary,\n    print_overfit_guard_summary\n)\n\n# Compute comprehensive summary\nsummary = compute_overfit_guard_summary(\n    history_baseline=history_without_guard,\n    history_guard=history_with_guard,\n    test_metric_baseline=test_without,\n    test_metric_guard=test_with,\n    monitor=monitor,\n    metric_name=metric_name,\n    higher_is_better=(task_type == 'classification')\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìä PROFESSIONAL REPORTING DEMO\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Professional Reporting (NEW!)\n\n**Generate publication-ready reports in multiple styles:**\n- **Research Style:** For academic papers, clean and precise\n- **Marketing Style:** For executives and stakeholders, with emojis and narrative\n- **Debug Style:** For troubleshooting, raw structured data\n\nThis feature is perfect for research papers, product demos, and internal debugging!",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}