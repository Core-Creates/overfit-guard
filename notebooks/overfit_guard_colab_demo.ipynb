{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Overfit Guard - Complete Demo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ›¡ï¸ Overfit Guard - Interactive Demo\n",
        "\n",
        "**Automatic Overfitting Detection & Correction for ML Models**\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-overfit--guard-blue?logo=github)](https://github.com/Core-Creates/overfit-guard)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Core-Creates/overfit-guard/blob/main/notebooks/overfit_guard_colab_demo.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ What This Demo Shows:\n",
        "1. âœ… Real-world dataset (Wisconsin Breast Cancer)\n",
        "2. âœ… Side-by-side comparison (with vs without guard)\n",
        "3. âœ… Automatic overfitting detection & correction\n",
        "4. âœ… Visual performance analysis\n",
        "5. âœ… Production-ready code examples\n",
        "\n",
        "**Estimated runtime:** 3-5 minutes\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸš€ Step 1: Installation\n",
        "\n",
        "First, we'll install Overfit Guard directly from GitHub:"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install from GitHub repo\n",
        "!pip install git+https://github.com/Core-Creates/overfit-guard.git\n",
        "!pip install scikit-learn matplotlib torch torchvision\n",
        "\n",
        "print(\"âœ… Installation complete!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installation\n",
        "import overfit_guard\n",
        "print(f\"âœ… Overfit Guard v{overfit_guard.__version__} installed successfully!\")\n",
        "print(f\"ğŸ“¦ Location: {overfit_guard.__file__}\")"
      ],
      "metadata": {
        "id": "verify_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¦ Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "imports_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from overfit_guard.integrations.pytorch import create_pytorch_monitor\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”¬ Step 3: Prepare Real-World Dataset\n",
        "\n",
        "**Wisconsin Breast Cancer Dataset:**\n",
        "- 569 samples (357 benign, 212 malignant)\n",
        "- 30 numerical features\n",
        "- Binary classification task\n",
        "- Medical diagnosis scenario"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "print(\"ğŸ“ Loading Wisconsin Breast Cancer dataset...\")\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(f\"\\nğŸ“Š Dataset Info:\")\n",
        "print(f\"   Samples: {X.shape[0]}\")\n",
        "print(f\"   Features: {X.shape[1]}\")\n",
        "print(f\"   Classes: {np.unique(y)} (0=malignant, 1=benign)\")\n",
        "print(f\"   Distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
        "\n",
        "# Split data: 70% train, 15% val, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"\\nâœ… Data Split:\")\n",
        "print(f\"   Training: {len(train_dataset)} samples\")\n",
        "print(f\"   Validation: {len(val_dataset)} samples\")\n",
        "print(f\"   Test: {len(test_dataset)} samples\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§  Step 4: Define Model Architecture"
      ],
      "metadata": {
        "id": "model_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastCancerClassifier(nn.Module):\n",
        "    \"\"\"Neural network for breast cancer classification.\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size=30):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            # Layer 1\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            \n",
        "            # Layer 2\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            \n",
        "            # Layer 3\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            \n",
        "            # Output\n",
        "            nn.Linear(16, 2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Test model\n",
        "test_model = BreastCancerClassifier(input_size=X_train.shape[1])\n",
        "print(f\"âœ… Model created successfully\")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in test_model.parameters()):,}\")"
      ],
      "metadata": {
        "id": "define_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ‹ï¸ Step 5: Training Functions"
      ],
      "metadata": {
        "id": "train_func_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total\n",
        "\n",
        "print(\"âœ… Training functions defined\")"
      ],
      "metadata": {
        "id": "train_funcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ†š Step 6: Comparative Training\n",
        "\n",
        "We'll train **two identical models**:\n",
        "1. **Baseline** - Standard training (no guard)\n",
        "2. **Protected** - With Overfit Guard enabled\n",
        "\n",
        "This demonstrates the real-world impact of automatic overfitting prevention."
      ],
      "metadata": {
        "id": "comparison_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(use_guard=True, num_epochs=50, verbose=True):\n",
        "    \"\"\"Run training experiment.\"\"\"\n",
        "    \n",
        "    # Reset seeds\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"ğŸ”§ Training {'WITH' if use_guard else 'WITHOUT'} Overfit Guard\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    # Create model\n",
        "    model = BreastCancerClassifier(input_size=X_train.shape[1]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "    \n",
        "    # Setup monitor\n",
        "    monitor = None\n",
        "    if use_guard:\n",
        "        monitor = create_pytorch_monitor(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            config={\n",
        "                'auto_correct': True,\n",
        "                'min_severity_for_correction': 'MODERATE',\n",
        "                'correction_cooldown': 5,\n",
        "                'log_level': 'WARNING'  # Less verbose\n",
        "            },\n",
        "            auto_correct=True\n",
        "        )\n",
        "        if verbose:\n",
        "            print(\"ğŸ›¡ï¸  Overfit Guard: ACTIVE\")\n",
        "            print(f\"   Detectors: {len(monitor.monitor.detectors)}\")\n",
        "            print(f\"   Correctors: {len(monitor.monitor.correctors)}\\n\")\n",
        "    \n",
        "    # Training loop\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        \n",
        "        # Check with monitor\n",
        "        if monitor:\n",
        "            results = monitor.on_epoch_end(\n",
        "                epoch=epoch,\n",
        "                model=model,\n",
        "                train_metrics={'loss': train_loss, 'accuracy': train_acc},\n",
        "                val_metrics={'loss': val_loss, 'accuracy': val_acc}\n",
        "            )\n",
        "            \n",
        "            if monitor.should_stop:\n",
        "                if verbose:\n",
        "                    print(f\"\\nâ¹ï¸  Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "        \n",
        "        # Print progress\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | \"\n",
        "                  f\"Gap: {(train_acc - val_acc):.4f}\")\n",
        "    \n",
        "    # Final test\n",
        "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\nğŸ“Š Final Results:\")\n",
        "        print(f\"   Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "        print(f\"   Train-Val Gap: {(history['train_acc'][-1] - history['val_acc'][-1]):.4f}\")\n",
        "        \n",
        "        if monitor:\n",
        "            summary = monitor.monitor.get_summary()\n",
        "            print(f\"\\n   ğŸ›¡ï¸  Guard Activity:\")\n",
        "            print(f\"      Detections: {summary['overfitting_detected']}\")\n",
        "            print(f\"      Corrections: {summary['corrections_applied']}\")\n",
        "            print(f\"      Rate: {summary['overfitting_rate']:.1%}\")\n",
        "    \n",
        "    return history, test_acc, monitor\n",
        "\n",
        "print(\"âœ… Training function ready\")"
      ],
      "metadata": {
        "id": "run_training_func"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run BASELINE (without guard)\n",
        "history_baseline, test_acc_baseline, _ = run_training(use_guard=False, num_epochs=50)"
      ],
      "metadata": {
        "id": "train_baseline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run WITH GUARD\n",
        "history_guard, test_acc_guard, monitor = run_training(use_guard=True, num_epochs=50)"
      ],
      "metadata": {
        "id": "train_guard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Š Step 7: Visual Comparison"
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "epochs_baseline = range(1, len(history_baseline['train_loss']) + 1)\n",
        "epochs_guard = range(1, len(history_guard['train_loss']) + 1)\n",
        "\n",
        "# Loss comparison\n",
        "axes[0, 0].plot(epochs_baseline, history_baseline['train_loss'], 'b-', label='Train', linewidth=2, alpha=0.8)\n",
        "axes[0, 0].plot(epochs_baseline, history_baseline['val_loss'], 'r-', label='Val', linewidth=2, alpha=0.8)\n",
        "axes[0, 0].set_title('Loss - WITHOUT Overfit Guard', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Loss', fontsize=11)\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(epochs_guard, history_guard['train_loss'], 'b-', label='Train', linewidth=2, alpha=0.8)\n",
        "axes[0, 1].plot(epochs_guard, history_guard['val_loss'], 'r-', label='Val', linewidth=2, alpha=0.8)\n",
        "axes[0, 1].set_title('Loss - WITH Overfit Guard âœ…', fontsize=14, fontweight='bold', color='green')\n",
        "axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Loss', fontsize=11)\n",
        "axes[0, 1].legend(fontsize=10)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy comparison\n",
        "axes[1, 0].plot(epochs_baseline, history_baseline['train_acc'], 'b-', label='Train', linewidth=2, alpha=0.8)\n",
        "axes[1, 0].plot(epochs_baseline, history_baseline['val_acc'], 'r-', label='Val', linewidth=2, alpha=0.8)\n",
        "axes[1, 0].set_title('Accuracy - WITHOUT Overfit Guard', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Accuracy', fontsize=11)\n",
        "axes[1, 0].legend(fontsize=10)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].plot(epochs_guard, history_guard['train_acc'], 'b-', label='Train', linewidth=2, alpha=0.8)\n",
        "axes[1, 1].plot(epochs_guard, history_guard['val_acc'], 'r-', label='Val', linewidth=2, alpha=0.8)\n",
        "axes[1, 1].set_title('Accuracy - WITH Overfit Guard âœ…', fontsize=14, fontweight='bold', color='green')\n",
        "axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Accuracy', fontsize=11)\n",
        "axes[1, 1].legend(fontsize=10)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ“ˆ Plots generated successfully!\")"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ† Step 8: Final Results & Analysis"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ† FINAL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Baseline stats\n",
        "gap_baseline = history_baseline['train_acc'][-1] - history_baseline['val_acc'][-1]\n",
        "print(\"\\nğŸ“Š WITHOUT Overfit Guard (Baseline):\")\n",
        "print(f\"   Test Accuracy: {test_acc_baseline:.4f} ({test_acc_baseline*100:.2f}%)\")\n",
        "print(f\"   Train-Val Gap: {gap_baseline:.4f}\")\n",
        "print(f\"   Final Train Acc: {history_baseline['train_acc'][-1]:.4f}\")\n",
        "print(f\"   Final Val Acc: {history_baseline['val_acc'][-1]:.4f}\")\n",
        "\n",
        "# Guard stats\n",
        "gap_guard = history_guard['train_acc'][-1] - history_guard['val_acc'][-1]\n",
        "summary = monitor.monitor.get_summary()\n",
        "\n",
        "print(\"\\nğŸ›¡ï¸  WITH Overfit Guard:\")\n",
        "print(f\"   Test Accuracy: {test_acc_guard:.4f} ({test_acc_guard*100:.2f}%)\")\n",
        "print(f\"   Train-Val Gap: {gap_guard:.4f}\")\n",
        "print(f\"   Final Train Acc: {history_guard['train_acc'][-1]:.4f}\")\n",
        "print(f\"   Final Val Acc: {history_guard['val_acc'][-1]:.4f}\")\n",
        "\n",
        "# Improvements\n",
        "test_improvement = (test_acc_guard - test_acc_baseline) * 100\n",
        "gap_reduction = gap_baseline - gap_guard\n",
        "gap_reduction_pct = (gap_reduction / abs(gap_baseline)) * 100 if gap_baseline != 0 else 0\n",
        "\n",
        "print(\"\\nğŸ’¡ Improvement:\")\n",
        "print(f\"   Test Accuracy: {test_improvement:+.2f}% {'âœ…' if test_improvement >= 0 else 'âš ï¸'}\")\n",
        "print(f\"   Gap Reduction: {gap_reduction:+.4f} ({gap_reduction_pct:+.1f}%) {'âœ…' if gap_reduction > 0 else 'âš ï¸'}\")\n",
        "\n",
        "# Guard activity\n",
        "print(f\"\\nğŸ”§ Guard Activity:\")\n",
        "print(f\"   Detections: {summary['overfitting_detected']}\")\n",
        "print(f\"   Corrections: {summary['corrections_applied']}\")\n",
        "print(f\"   Detection Rate: {summary['overfitting_rate']:.1%}\")\n",
        "print(f\"   Active Detectors: {summary['active_detectors']}\")\n",
        "print(f\"   Active Correctors: {summary['active_correctors']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\nğŸ“ Interpretation:\")\n",
        "if test_improvement > 0:\n",
        "    print(\"   âœ… Test accuracy IMPROVED with Overfit Guard\")\n",
        "elif test_improvement == 0:\n",
        "    print(\"   âœ… Test accuracy MAINTAINED (no degradation)\")\n",
        "else:\n",
        "    print(f\"   âš ï¸  Test accuracy slightly decreased ({abs(test_improvement):.2f}%)\")\n",
        "    print(\"      This can happen when preventing overfitting on well-behaved datasets\")\n",
        "\n",
        "if gap_reduction > 0:\n",
        "    print(f\"   âœ… Train-val gap REDUCED by {gap_reduction_pct:.1f}% (better generalization)\")\n",
        "else:\n",
        "    print(\"   âš ï¸  Gap increased (model may need different tuning)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "final_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ Key Takeaways\n",
        "\n",
        "### âœ… What Overfit Guard Does:\n",
        "1. **Automatic Detection**: Monitors train/val metrics in real-time\n",
        "2. **Smart Corrections**: Adjusts regularization & hyperparameters automatically\n",
        "3. **Early Stopping**: Prevents wasted training time\n",
        "4. **Zero Configuration**: Works out-of-the-box with sensible defaults\n",
        "\n",
        "### ğŸ“ When to Use Overfit Guard:\n",
        "- âœ… Deep neural networks with many parameters\n",
        "- âœ… Limited training data\n",
        "- âœ… Production ML pipelines\n",
        "- âœ… Automated training workflows\n",
        "- âœ… Research experiments\n",
        "\n",
        "### ğŸ’» Integration is Simple:\n",
        "```python\n",
        "from overfit_guard.integrations.pytorch import create_pytorch_monitor\n",
        "\n",
        "# Just add these 3 lines to your training loop:\n",
        "monitor = create_pytorch_monitor(\n",
        "    model=model, \n",
        "    optimizer=optimizer, \n",
        "    auto_correct=True\n",
        ")\n",
        "\n",
        "# Then in your training loop:\n",
        "monitor.on_epoch_end(epoch, model, train_metrics, val_metrics)\n",
        "```\n",
        "\n",
        "### ğŸ“š Learn More:\n",
        "- ğŸ“¦ [PyPI Package](https://pypi.org/project/overfit-guard/)\n",
        "- ğŸ’» [GitHub Repository](https://github.com/Core-Creates/overfit-guard)\n",
        "- ğŸ“– [Full Documentation](https://github.com/Core-Creates/overfit-guard/blob/main/README.md)\n",
        "- ğŸ› [Report Issues](https://github.com/Core-Creates/overfit-guard/issues)\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "1. Try Overfit Guard on your own datasets\n",
        "2. Experiment with different configurations\n",
        "3. Compare with manual overfitting prevention\n",
        "4. Share feedback on GitHub!\n",
        "\n",
        "---\n",
        "\n",
        "**Made with â¤ï¸ by the Overfit Guard team**\n",
        "\n",
        "[![Star on GitHub](https://img.shields.io/github/stars/Core-Creates/overfit-guard?style=social)](https://github.com/Core-Creates/overfit-guard)"
      ],
      "metadata": {
        "id": "takeaways"
      }
    }
  ]
}
